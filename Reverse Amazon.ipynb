{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1062477-4410-4569-b44e-caf25a849a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (2.32.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: openpyxl in /opt/anaconda3/lib/python3.12/site-packages (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: et-xmlfile in /opt/anaconda3/lib/python3.12/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21604a88-1536-4b67-8880-b74fa0c342b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching search results for 'Adeptus Mechanicus Sicarians Warhammer 40,000'\n",
      "Error fetching search results for 'Games Workshop 99070101036\" Dark Angels Primaris Upgrades Miniature'\n",
      "Error fetching search results for 'Games Workshop - Warhammer 40,000 - Kill Team: Hand Of The Archon [video game]'\n",
      "Error fetching search results for 'Games Workshop - Warhammer 40,000 - Leagues of Votann: Hearthkyn Warriors'\n",
      "Error fetching search results for 'Games Workshop - 99120112043 - Warhammer 40,000 - Combat Patrol: Drukhari'\n",
      "Error fetching search results for 'Warhammer 40,000: Space Marines - Tactical Squad'\n",
      "Error fetching search results for 'Warhammer Age of Sigmar - Kharadron Overlords Vanguard'\n",
      "Skipping invalid title: nan\n",
      "Error fetching search results for 'Games Workshop 99120206023 Skaven Pestilens Verminlord Corruptor Miniature'\n",
      "Error fetching search results for 'Games Workshop - Warhammer 40,000 - Adepta Sororitas Penitent Engines/Engines of Redemption'\n",
      "Error fetching search results for 'Games Workshop 99129915029 \"Warhammer Age of Sigmar Blue and Brimstone Horrors Action Figure'\n",
      "Error fetching search results for 'Games Workshop - Middle Earth Strategy Battle Game: The Lord of The Rings - Isengard Battlehost'\n",
      "Error fetching search results for 'Games Workshop Death Guard Daemon Primarch Mortarion Warhammer 40,000, 5 years to 99 years'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 77\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 77\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[3], line 60\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m title \u001b[38;5;129;01min\u001b[39;00m product_titles:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(title, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m title\u001b[38;5;241m.\u001b[39mstrip():  \u001b[38;5;66;03m# Check for valid title\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m         amazon_link, asin \u001b[38;5;241m=\u001b[39m search_amazon(title)\n\u001b[1;32m     61\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     62\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProduct Title\u001b[39m\u001b[38;5;124m\"\u001b[39m: title,\n\u001b[1;32m     63\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAmazon Link\u001b[39m\u001b[38;5;124m\"\u001b[39m: amazon_link,\n\u001b[1;32m     64\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mASIN\u001b[39m\u001b[38;5;124m\"\u001b[39m: asin\n\u001b[1;32m     65\u001b[0m         })\n\u001b[1;32m     66\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Pause between requests to avoid being blocked\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m, in \u001b[0;36msearch_amazon\u001b[0;34m(product_title)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Define headers to mimic a real browser request\u001b[39;00m\n\u001b[1;32m     12\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m }\n\u001b[0;32m---> 16\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(search_url, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Check if the request was successful\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/adapters.py:589\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    586\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    590\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    591\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    592\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    593\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    594\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    595\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    596\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[1;32m    599\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    600\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    601\u001b[0m     )\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    790\u001b[0m     conn,\n\u001b[1;32m    791\u001b[0m     method,\n\u001b[1;32m    792\u001b[0m     url,\n\u001b[1;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[1;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[1;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    802\u001b[0m )\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/http/client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1428\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/socket.py:708\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Function to search Amazon and extract the product URL and ASIN\n",
    "def search_amazon(product_title):\n",
    "    # Construct the search URL\n",
    "    search_url = f\"https://www.amazon.com/s?k={'+'.join(product_title.split())}\"\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching search results for '{product_title}'\")\n",
    "        return None, None\n",
    "\n",
    "    # Parse the page content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find product links and ASINs in the search results\n",
    "    products = soup.find_all(\"div\", {\"data-component-type\": \"s-search-result\"})\n",
    "    \n",
    "    for product in products:\n",
    "        link = product.find(\"a\", {\"class\": \"a-link-normal\"})\n",
    "        if link:\n",
    "            # Construct the full product URL\n",
    "            product_url = \"https://www.amazon.com\" + link['href']\n",
    "            \n",
    "            # Extract the ASIN from the product URL\n",
    "            asin = product_url.split('/dp/')[1][:10]  # Extract ASIN from the URL\n",
    "            return product_url, asin\n",
    "\n",
    "    return None, None\n",
    "\n",
    "# Function to load product titles from the Excel file\n",
    "def load_product_titles(excel_file_path):\n",
    "    df = pd.read_excel(excel_file_path)\n",
    "    return df['Title'].tolist()\n",
    "\n",
    "# Main function to orchestrate the scraping and saving process\n",
    "def main():\n",
    "    # Specify the path to your Excel file\n",
    "    excel_file_path = \"/Users/user/Downloads/Amazon Scrapping Interview Task (1) (3).xlsx\"  # Update this path\n",
    "\n",
    "    # Load product titles from the Excel file\n",
    "    product_titles = load_product_titles(excel_file_path)\n",
    "\n",
    "    # Data storage for results\n",
    "    results = []\n",
    "\n",
    "    # Iterate through each product title and search\n",
    "    for title in product_titles:\n",
    "        if isinstance(title, str) and title.strip():  # Check for valid title\n",
    "            amazon_link, asin = search_amazon(title)\n",
    "            results.append({\n",
    "                \"Product Title\": title,\n",
    "                \"Amazon Link\": amazon_link,\n",
    "                \"ASIN\": asin\n",
    "            })\n",
    "            time.sleep(2)  # Pause between requests to avoid being blocked\n",
    "        else:\n",
    "            print(f\"Skipping invalid title: {title}\")\n",
    "\n",
    "    # Convert results to a DataFrame and save to Excel\n",
    "    df_results = pd.DataFrame(results)\n",
    "    output_file_path = \"amazon_product_data.xlsx\"\n",
    "    df_results.to_excel(output_file_path, index=False)\n",
    "    print(f\"Data saved to {output_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "172b866c-6b99-48a8-b2e0-7ac5b2d236fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /opt/anaconda3/lib/python3.12/site-packages (4.25.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /opt/anaconda3/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.2)\n",
      "Requirement already satisfied: trio~=0.17 in /opt/anaconda3/lib/python3.12/site-packages (from selenium) (0.26.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /opt/anaconda3/lib/python3.12/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /opt/anaconda3/lib/python3.12/site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /opt/anaconda3/lib/python3.12/site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /opt/anaconda3/lib/python3.12/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /opt/anaconda3/lib/python3.12/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /opt/anaconda3/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90444067-49fe-4ebd-830c-247fa791ae9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for: Adeptus Mechanicus Sicarians Warhammer 40,000\n",
      "Searching for: Games Workshop 99070101036\" Dark Angels Primaris Upgrades Miniature\n",
      "Searching for: Games Workshop - Warhammer 40,000 - Kill Team: Hand Of The Archon [video game]\n",
      "Searching for: Games Workshop - Warhammer 40,000 - Leagues of Votann: Hearthkyn Warriors\n",
      "Searching for: Games Workshop - 99120112043 - Warhammer 40,000 - Combat Patrol: Drukhari\n",
      "Error fetching data for Games Workshop - 99120112043 - Warhammer 40,000 - Combat Patrol: Drukhari: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"div.s-main-slot div[data-component-type=\"s-search-result\"]\"}\n",
      "  (Session info: chrome=129.0.6668.90); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000100fac248 cxxbridge1$str$ptr + 1907280\n",
      "1   chromedriver                        0x0000000100fa4730 cxxbridge1$str$ptr + 1875768\n",
      "2   chromedriver                        0x0000000100bb8260 cxxbridge1$string$len + 89488\n",
      "3   chromedriver                        0x0000000100bfc50c cxxbridge1$string$len + 368700\n",
      "4   chromedriver                        0x0000000100c367d0 cxxbridge1$string$len + 606976\n",
      "5   chromedriver                        0x0000000100bf112c cxxbridge1$string$len + 322652\n",
      "6   chromedriver                        0x0000000100bf1d7c cxxbridge1$string$len + 325804\n",
      "7   chromedriver                        0x0000000100f744d8 cxxbridge1$str$ptr + 1678560\n",
      "8   chromedriver                        0x0000000100f78e40 cxxbridge1$str$ptr + 1697352\n",
      "9   chromedriver                        0x0000000100f595ec cxxbridge1$str$ptr + 1568244\n",
      "10  chromedriver                        0x0000000100f79710 cxxbridge1$str$ptr + 1699608\n",
      "11  chromedriver                        0x0000000100f4ab90 cxxbridge1$str$ptr + 1508248\n",
      "12  chromedriver                        0x0000000100f95828 cxxbridge1$str$ptr + 1814576\n",
      "13  chromedriver                        0x0000000100f95980 cxxbridge1$str$ptr + 1814920\n",
      "14  chromedriver                        0x0000000100fa43d0 cxxbridge1$str$ptr + 1874904\n",
      "15  libsystem_pthread.dylib             0x000000018e206f94 _pthread_start + 136\n",
      "16  libsystem_pthread.dylib             0x000000018e201d34 thread_start + 8\n",
      "\n",
      "Searching for: Warhammer 40,000: Space Marines - Tactical Squad\n",
      "Searching for: GAMES WORKSHOP Warhammer 40k - Empire Tau Commander Shadowsun\n",
      "Searching for: Warhammer Age of Sigmar - Kharadron Overlords Vanguard\n",
      "Skipping invalid title: nan\n",
      "Searching for: Games Workshop 99120206023 Skaven Pestilens Verminlord Corruptor Miniature\n",
      "Searching for: Games Workshop - Warhammer 40,000 - Adepta Sororitas Penitent Engines/Engines of Redemption\n",
      "Searching for: Games Workshop 99129915029 \"Warhammer Age of Sigmar Blue and Brimstone Horrors Action Figure\n",
      "Error fetching data for Games Workshop 99129915029 \"Warhammer Age of Sigmar Blue and Brimstone Horrors Action Figure: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"div.s-main-slot div[data-component-type=\"s-search-result\"]\"}\n",
      "  (Session info: chrome=129.0.6668.90); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000100fac248 cxxbridge1$str$ptr + 1907280\n",
      "1   chromedriver                        0x0000000100fa4730 cxxbridge1$str$ptr + 1875768\n",
      "2   chromedriver                        0x0000000100bb8260 cxxbridge1$string$len + 89488\n",
      "3   chromedriver                        0x0000000100bfc50c cxxbridge1$string$len + 368700\n",
      "4   chromedriver                        0x0000000100c367d0 cxxbridge1$string$len + 606976\n",
      "5   chromedriver                        0x0000000100bf112c cxxbridge1$string$len + 322652\n",
      "6   chromedriver                        0x0000000100bf1d7c cxxbridge1$string$len + 325804\n",
      "7   chromedriver                        0x0000000100f744d8 cxxbridge1$str$ptr + 1678560\n",
      "8   chromedriver                        0x0000000100f78e40 cxxbridge1$str$ptr + 1697352\n",
      "9   chromedriver                        0x0000000100f595ec cxxbridge1$str$ptr + 1568244\n",
      "10  chromedriver                        0x0000000100f79710 cxxbridge1$str$ptr + 1699608\n",
      "11  chromedriver                        0x0000000100f4ab90 cxxbridge1$str$ptr + 1508248\n",
      "12  chromedriver                        0x0000000100f95828 cxxbridge1$str$ptr + 1814576\n",
      "13  chromedriver                        0x0000000100f95980 cxxbridge1$str$ptr + 1814920\n",
      "14  chromedriver                        0x0000000100fa43d0 cxxbridge1$str$ptr + 1874904\n",
      "15  libsystem_pthread.dylib             0x000000018e206f94 _pthread_start + 136\n",
      "16  libsystem_pthread.dylib             0x000000018e201d34 thread_start + 8\n",
      "\n",
      "Searching for: Games Workshop - Middle Earth Strategy Battle Game: The Lord of The Rings - Isengard Battlehost\n",
      "Searching for: Games Workshop Death Guard Daemon Primarch Mortarion Warhammer 40,000, 5 years to 99 years\n",
      "Searching for: Games Workshop 99120102078\" Death Guard Plague Marines Miniature, Black, 12 years to 99 years\n",
      "Searching for: Games Workshop Warhammer 40k - Space Marine Primaris Invictor Tactical Warsuit 48-98 Black\n",
      "Searching for: -\n",
      "Searching for: Warhammer 40,000: Adepta Sororitas Celestian Sacresants\n",
      "Searching for: Games Workshop - Middle Earth Strategy Battle Game: The Lord of The Rings - Mordor Battlehost\n",
      "Searching for: Warhammer Tau Empire Pathfinder Team 40,000\n",
      "Searching for: Warhammer 40,000: Introductory Set\n",
      "Searching for: Games Workshop - Warhammer 40,000 - Space Marines: Jump Pack Intercessors\n",
      "Searching for: Warhammer Age of Sigmar Games Workshop Slaves to Darkness: Chaos Chosen\n",
      "Searching for: Games Workshop Legion Cataphractii Terminator Squad\n",
      "Searching for: Warhammer 40K Ultramarines Roboute Guilliman\n",
      "Searching for: Games Workshop - Warhammer 40,000 - Chaos Space Marines Abaddon The Despoiler\n",
      "Searching for: Space Marines Primaris Apothecary Warhammer 40,000\n",
      "Searching for: Games Workshop Warhammer 40k - Space Marine Primaris Quad Invader\n",
      "Searching for: Warhammer AoS - Sylvaneth Warsong Revenant\n",
      "Searching for: Warhammer 40k - Genestealer Cults Neophyte Hybrids\n",
      "Searching for: Games Workshop - Warhammer 40,000 - Aeldari: Rangers\n",
      "Searching for: Games Workshop - Warhammer 40,000 - Leagues of Votann: Hernkyn Pioneers\n",
      "Searching for: Games Workshop - Warhammer 40,000 - Adepta Sororitas: Aestred Thurga Relinquant at Arms\n",
      "Searching for: Games Workshop Warhammer NECROMUNDA: PALANITE Enforcer Patrol\n",
      "Searching for: Warhammer Games Workshop 40,000 - Chaos Space Marines Fabius Bile\n",
      "Searching for: Games Workshop - Warhammer 40,000 - Kill Team: Legionaries\n",
      "Searching for: Games Workshop - Warhammer 40,000 - Leagues of Votann: Grimnyr\n",
      "Searching for: Ork Stormboyz Warhammer 40K Miniature Set\n",
      "Searching for: Games Workshop - Warhammer 40,000 - Blood Angels: Death Company Intercessors\n",
      "Searching for: Games Workshop 64-71 Warhammer Middle Earth - Fellowship of The Ring\n",
      "Searching for: Warhammer 40,000: Tyranids - Lictor\n",
      "Searching for: Combat Patrol Leagues of Votann Warhammer 40,000\n",
      "Searching for: Games Workshop 99120218010 Start Collecting Stormcast Eternals Tabletop and Miniature Gaming,12 years to 99 years\n",
      "Error fetching data for Games Workshop 99120218010 Start Collecting Stormcast Eternals Tabletop and Miniature Gaming,12 years to 99 years: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"div.s-main-slot div[data-component-type=\"s-search-result\"]\"}\n",
      "  (Session info: chrome=129.0.6668.90); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000100fac248 cxxbridge1$str$ptr + 1907280\n",
      "1   chromedriver                        0x0000000100fa4730 cxxbridge1$str$ptr + 1875768\n",
      "2   chromedriver                        0x0000000100bb8260 cxxbridge1$string$len + 89488\n",
      "3   chromedriver                        0x0000000100bfc50c cxxbridge1$string$len + 368700\n",
      "4   chromedriver                        0x0000000100c367d0 cxxbridge1$string$len + 606976\n",
      "5   chromedriver                        0x0000000100bf112c cxxbridge1$string$len + 322652\n",
      "6   chromedriver                        0x0000000100bf1d7c cxxbridge1$string$len + 325804\n",
      "7   chromedriver                        0x0000000100f744d8 cxxbridge1$str$ptr + 1678560\n",
      "8   chromedriver                        0x0000000100f78e40 cxxbridge1$str$ptr + 1697352\n",
      "9   chromedriver                        0x0000000100f595ec cxxbridge1$str$ptr + 1568244\n",
      "10  chromedriver                        0x0000000100f79710 cxxbridge1$str$ptr + 1699608\n",
      "11  chromedriver                        0x0000000100f4ab90 cxxbridge1$str$ptr + 1508248\n",
      "12  chromedriver                        0x0000000100f95828 cxxbridge1$str$ptr + 1814576\n",
      "13  chromedriver                        0x0000000100f95980 cxxbridge1$str$ptr + 1814920\n",
      "14  chromedriver                        0x0000000100fa43d0 cxxbridge1$str$ptr + 1874904\n",
      "15  libsystem_pthread.dylib             0x000000018e206f94 _pthread_start + 136\n",
      "16  libsystem_pthread.dylib             0x000000018e201d34 thread_start + 8\n",
      "\n",
      "Searching for: Warhammer - Horus Heresy: CERASTUS Knight Acheron\n",
      "Searching for: Warhammer 40,000: Necrons - Canoptek Spyder\n",
      "Searching for: Games Workshop - Warhammer 40,000 - Leagues of Votann: The Ancestors Wrath\n",
      "Searching for: Games Workshop - Warhammer 40,000 - Combat Patrol: Genestealer Cults\n",
      "Searching for: Games Workshop - Warhammer 40,000 - Boarding Patrol: Adeptus Mechanicus\n",
      "Searching for: Orks - Goff Rocker\n",
      "Searching for: Warhammer 40,000: Necromunda - Gawdor Redemptionists\n",
      "Searching for: Games Workshop - Warhammer 40,000 - Necrons Chronomancer\n",
      "Searching for: Games Workshop Warhammer 40k - Grey Knights Castellan Crowe\n",
      "Searching for: Games Workshop Warhammer 40k - Astra Militarum Lord Castellan Ursula Creed\n",
      "Searching for: Games Workshop Warhammer 40k - Astra Militarum Solar Lord Leontus\n",
      "Searching for: Games Workshop Warhammer 40k - Kill Team : Kasrkins\n",
      "Searching for: Warhammer 40,000: Space Wolves Grey Hunters\n",
      "Data saved to amazon_product_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "driver.get('https://www.amazon.com')\n",
    "\n",
    "# Function to search Amazon and extract product URL and ASIN\n",
    "def search_amazon(product_title, driver):\n",
    "    # Construct the search URL\n",
    "    search_url = f\"https://www.amazon.com/s?k={'+'.join(product_title.split())}\"\n",
    "\n",
    "    # Load the search page\n",
    "    driver.get(search_url)\n",
    "\n",
    "    # Wait for the page to load\n",
    "    time.sleep(3)\n",
    "\n",
    "    try:\n",
    "        # Find the first product in the search results\n",
    "        first_product = driver.find_element(By.CSS_SELECTOR, 'div.s-main-slot div[data-component-type=\"s-search-result\"]')\n",
    "        link = first_product.find_element(By.CSS_SELECTOR, 'a.a-link-normal')\n",
    "\n",
    "        # Get the product URL\n",
    "        product_url = link.get_attribute('href')\n",
    "        \n",
    "        # Extract ASIN from the URL\n",
    "        if \"/dp/\" in product_url:\n",
    "            asin = product_url.split('/dp/')[1][:10]  # Extract ASIN from the URL\n",
    "        else:\n",
    "            asin = None\n",
    "        \n",
    "        return product_url, asin\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {product_title}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Function to load product titles from Excel file\n",
    "def load_product_titles(excel_file_path):\n",
    "    df = pd.read_excel(excel_file_path)\n",
    "    return df['Title'].tolist()\n",
    "\n",
    "# Main function to scrape data and save to an Excel file\n",
    "def main():\n",
    "    # Specify the path to your Excel file\n",
    "    excel_file_path = \"/Users/user/Downloads/Amazon Scrapping Interview Task (1) (3).xlsx\"  # Update this path\n",
    "\n",
    "    # Load product titles from the Excel file\n",
    "    product_titles = load_product_titles(excel_file_path)\n",
    "\n",
    "    # Data storage for results\n",
    "    results = []\n",
    "\n",
    "    # Iterate through each product title and search\n",
    "    for title in product_titles:\n",
    "        if isinstance(title, str) and title.strip():  # Check for valid title\n",
    "            print(f\"Searching for: {title}\")\n",
    "            amazon_link, asin = search_amazon(title, driver)\n",
    "            results.append({\n",
    "                \"Product Title\": title,\n",
    "                \"Amazon Link\": amazon_link,\n",
    "                \"ASIN\": asin\n",
    "            })\n",
    "            time.sleep(2)  # Pause between requests to avoid being blocked\n",
    "        else:\n",
    "            print(f\"Skipping invalid title: {title}\")\n",
    "\n",
    "    # Close the WebDriver session\n",
    "    driver.quit()\n",
    "\n",
    "    # Convert results to a DataFrame and save to Excel\n",
    "    df_results = pd.DataFrame(results)\n",
    "    output_file_path = \"amazon_product_data.xlsx\"\n",
    "    df_results.to_excel(output_file_path, index=False)\n",
    "    print(f\"Data saved to {output_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2af3e7-1abc-469f-9928-861bc8b8db6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
